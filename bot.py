import logging
import os
import json
import re
import sqlite3
import numpy as np
from numpy.linalg import norm

from aiogram import Bot, Dispatcher, F
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import CommandStart

from openai import OpenAI
import asyncio

# ---------------------------
# ENV
# ---------------------------
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN not set")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY not set")

# ---------------------------
# Bot init (Aiogram 3.7+)
# ---------------------------
bot = Bot(token=TELEGRAM_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

# ---------------------------
# Load lex_base + embeddings
# ---------------------------
with open("lex_base.json", "r", encoding="utf-8") as f:
    LEX_BASE = json.load(f)

VECTORS = {}
if os.path.exists("embeddings/tk_vectors.pkl"):
    import pickle
    with open("embeddings/tk_vectors.pkl", "rb") as f:
        VECTORS = pickle.load(f)

# ---------------------------
# Inline language keyboard
# ---------------------------
INLINE_LANG = InlineKeyboardMarkup(inline_keyboard=[
    [InlineKeyboardButton(text="üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data="lang_ru"),
     InlineKeyboardButton(text="üá∫üáø –é–∑–±–µ–∫—á–∞", callback_data="lang_uz")]
])

user_lang = {}  # user_id -> "ru"/"uz"

# ---------------------------
# utils
# ---------------------------
def cosine(a, b):
    a = np.array(a); b = np.array(b)
    denom = np.linalg.norm(a) * np.linalg.norm(b)
    if denom == 0:
        return -1.0
    return float(np.dot(a, b) / denom)

def is_short_non_hr(text: str) -> bool:
    # quick heuristic: very short messages (emoji/hi) ‚Äî treat as non-HR probable
    t = text.strip()
    if len(t) <= 3:
        return True
    # contains only emoji / punctuation
    if re.fullmatch(r"[\W_]+", t):
        return True
    return False

# ---------------------------
# Start handler
# ---------------------------
@dp.message(CommandStart())
async def cmd_start(message: Message):
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ / Tilni tanlang:", reply_markup=INLINE_LANG)

# ---------------------------
# Language picker (remove keyboard after choice)
# ---------------------------
@dp.callback_query(F.data.startswith("lang_"))
async def lang_picker(callback):
    uid = callback.from_user.id

    if callback.data == "lang_ru":
        user_lang[uid] = "ru"
        await callback.message.edit_reply_markup(reply_markup=None)  # remove inline keyboard
        await callback.message.answer("–Ø–∑—ã–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: –†—É—Å—Å–∫–∏–π üá∑üá∫")
    else:
        user_lang[uid] = "uz"
        await callback.message.edit_reply_markup(reply_markup=None)
        await callback.message.answer("Til o‚Äòrnatildi: –é–∑bek—á–∞ üá∫üáø")

    await callback.answer()

# ---------------------------
# Classification via GPT: is this HR-related?
# ---------------------------
async def classify_hr(question: str) -> str:
    """
    Return "HR" or "NOT_HR".
    Uses a deterministic prompt (temperature=0).
    """
    try:
        prompt = (
            "–ö—Ä–∞—Ç–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π: —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –í–û–ü–†–û–°–û–ú –ü–û –¢–†–£–î–û–í–û–ú–£ –ö–û–î–ï–ö–°–£/HR (–æ—Ç–≤–µ—Ç–∏ —Ç–æ–ª—å–∫–æ 'HR' –∏–ª–∏ 'NOT_HR').\n\n"
            f"–¢–µ–∫—Å—Ç: {question}\n\n"
            "–ü—Ä–∞–≤–∏–ª–∞: –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —è–≤–Ω–æ –ø—Ä–æ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ, –æ—Ç–ø—É—Å–∫, –±–æ–ª—å–Ω–∏—á–Ω—ã–π, –∑–∞—Ä–ø–ª–∞—Ç—É, –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏, –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É, "
            "–ø—Ä–∏—ë–º/—É–≤–æ–ª—å–Ω–µ–Ω–∏–µ, —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ, —Ä–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã, –ø—Ä–∞–≤–∞ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ ‚Äî –æ—Ç–≤–µ—Ç—å HR. "
            "–ï—Å–ª–∏ —ç—Ç–æ –±—ã—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–ø—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞, emoji), –ª–∏—á–Ω—ã–π —á–∞—Ç, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –∏–ª–∏ –Ω–µ—è—Å–Ω—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç ‚Äî –æ—Ç–≤–µ—Ç—å NOT_HR."
        )
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ 'HR' –∏–ª–∏ 'NOT_HR'."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=8
        )
        out = resp.choices[0].message.content.strip().upper()
        if out.startswith("HR"):
            return "HR"
        return "NOT_HR"
    except Exception as e:
        logging.exception("Classifier error: %s", e)
        # fallback heuristics
        if is_short_non_hr(question):
            return "NOT_HR"
        # fallback: if contains HR keywords -> HR
        keywords = ["—É–≤–æ–ª", "—É–≤–æ–ª—å–Ω", "–æ—Ç–ø—É—Å–∫", "–±–æ–ª—å–Ω–∏—á", "–¥–æ–≥–æ–≤–æ—Ä", "—Ç—Ä—É–¥", "–∑–∞—Ä–ø", "–∫–æ–º–ø–µ–Ω—Å", "–¥–∏—Å—Ü–∏–ø–ª", "—Å–æ–∫—Ä–∞—â", "—Ä–∞–±–æ—Ç–Ω–∏–∫", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "—Å—Ç–∞—Ç—å—è", "–º–æ–¥–¥–∞"]
        low = question.lower()
        if any(k in low for k in keywords):
            return "HR"
        return "NOT_HR"

# ---------------------------
# Main message handler
# ---------------------------
@dp.message(F.text)
async def answer_user(message: Message):
    uid = message.from_user.id
    text = message.text.strip()

    if uid not in user_lang:
        await message.answer("–ü—Ä–∏–≤–µ—Ç! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ —Å–Ω–∞—á–∞–ª–∞:", reply_markup=INLINE_LANG)
        return

    lang = user_lang[uid]
    await message.chat.do("typing")

    # Quick non-HR checks
    if is_short_non_hr(text):
        if lang == "ru":
            reply = "–ü—Ä–∏–≤–µ—Ç! üëã –£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ ‚Äî —è –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –†–µ—Å–ø—É–±–ª–∏–∫–∏ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω. –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ, –æ—Ç–ø—É—Å–∫, –±–æ–ª—å–Ω–∏—á–Ω—ã–π, –≥—Ä–∞—Ñ–∏–∫ –∏–ª–∏ –ø—Ä–∞–≤–∞ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ ‚Äî –ø–æ–º–æ–≥—É!"
        else:  # uz
            reply = "–°–∞–ª–æ–º! üëã “≤–∞–º–º–∞—Å–∏ –∂–æ–π–∏–¥–∞ ‚Äî –º–µ–Ω –é–∑–±–µ–∫–∏—Å—Ç–æ–Ω –ú–µ“≥–Ω–∞—Ç –∫–æ–¥–µ–∫—Å–∏ –±—û–π–∏—á–∞ —ë—Ä–¥–∞–º—á–∏–º–∞–Ω. –≠“≥—Ç–∏—Ä–æ–∑–ª–∞—Ä, –∏—à–¥–∞–Ω –±—û—à–∞—Ç–∏—à, —Ç–∞—ä—Ç–∏–ª, –∫–∞—Å–∞–ª–ª–∏–∫ –≤–∞ —Ö–æ–¥–∏–º “≥—É“õ—É“õ–ª–∞—Ä–∏ “≥–∞“õ–∏–¥–∞ —Å—û—Ä–∞—à–∏–Ω–≥ ‚Äî —ë—Ä–¥–∞–º –±–µ—Ä–∞–º–∞–Ω!"
        await message.answer(reply + "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: https://lex.uz/docs/6257291")
        return

    # Ask GPT classifier whether this is HR-related
    classification = await classify_hr(text)

    if classification == "NOT_HR":
        # Friendly reply (variant 2 style)
        if lang == "ru":
            reply = ("–ü—Ä–∏–≤–µ—Ç! üëã –£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ ‚Äî —è HR-–±–æ—Ç –ø–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–∞. "
                     "–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ —É–≤–æ–ª—å–Ω–µ–Ω–∏—é, –æ—Ç–ø—É—Å–∫—É, –±–æ–ª—å–Ω–∏—á–Ω–æ–º—É, —Ç—Ä—É–¥–æ–≤—ã–º –¥–æ–≥–æ–≤–æ—Ä–∞–º –∏–ª–∏ –ø—Ä–∞–≤–∞–º —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ ‚Äî —Å–ø—Ä–∞—à–∏–≤–∞–π—Ç–µ.")
        else:
            reply = ("–°–∞–ª–æ–º! üëã “≤–∞–º–º–∞—Å–∏ –∂–æ–π–∏–¥–∞ ‚Äî –º–µ–Ω –é–∑–±–µ–∫–∏—Å—Ç–æ–Ω –ú–µ“≥–Ω–∞—Ç –∫–æ–¥–µ–∫—Å–∏ –±—û–π–∏—á–∞ HR-–±–æ—Ç–º–∞–Ω. "
                     "–ê–≥–∞—Ä –∏—à–¥–∞–Ω –±—û—à–∞—Ç–∏—à, —Ç–∞—ä—Ç–∏–ª, –∫–∞—Å–∞–ª–ª–∏–∫, –º–µ“≥–Ω–∞—Ç —à–∞—Ä—Ç–Ω–æ–º–∞–ª–∞—Ä–∏ —ë–∫–∏ —Ö–æ–¥–∏–º “≥—É“õ—É“õ–ª–∞—Ä–∏ “≥–∞“õ–∏–¥–∞ —Å–∞–≤–æ–ª –±—û–ª—Å–∞ ‚Äî —Å—û—Ä–∞–Ω–≥.")
        await message.answer(reply + "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: https://lex.uz/docs/6257291")
        return

    # If here => classified as HR question
    # -------------------------------
    # 1) try extract article number (RU or UZ)
    article_id = None
    m1 = re.search(r"—Å—Ç–∞—Ç(—å—è|–∏)?\s*(\d+)", text.lower())
    m2 = re.search(r"(\d{1,4})\s*-\s*–º–æ–¥–¥–∞", text.lower())
    if m1:
        article_id = m1.group(2)
    elif m2:
        article_id = m2.group(1)

    # 2) semantic search if no article number
    if not article_id and VECTORS:
        try:
            emb = client.embeddings.create(model="text-embedding-3-small", input=text)
            qvec = np.array(emb.data[0].embedding)
            best_score = -999
            best_aid = None
            for aid, vec in VECTORS.items():
                score = cosine(qvec, np.array(vec))
                if score > best_score:
                    best_score = score
                    best_aid = aid
            # threshold: require some minimal similarity to accept (avoid random match)
            if best_score is not None and best_score >= 0.23:
                article_id = best_aid
            else:
                article_id = None
        except Exception as e:
            logging.exception("Embeddings search error: %s", e)
            article_id = None

    # 3) get article text if found
    article_text = ""
    if article_id and str(article_id) in LEX_BASE:
        article_text = LEX_BASE[str(article_id)].get(lang, "")

    # 4) Prepare strict system/user messages to avoid invented numbers
    system_msg = (
        "–¢—ã ‚Äî HR-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –†–µ—Å–ø—É–±–ª–∏–∫–∏ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω. "
        "–ï—Å–ª–∏ —Ç–µ–±–µ –ø–µ—Ä–µ–¥–∞–ª–∏ —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ ‚Äî –û–¢–í–ï–ß–ê–ô –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. "
        "–ù–ò–ö–ê–ö–ò–• –¥—Ä—É–≥–∏—Ö –Ω–æ–º–µ—Ä–æ–≤ —Å—Ç–∞—Ç–µ–π –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏ –Ω–µ –Ω–∞–∑—ã–≤–∞–π. "
        "–ï—Å–ª–∏ —Å—Ç–∞—Ç—å—è –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏: '–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ; —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ lex.uz' –∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä. "
        "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –¥–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏ –¥–ª—è –∫–∞–¥—Ä–æ–≤–∏–∫–∞."
    )

    if article_text:
        user_msg = (f"–í–æ–ø—Ä–æ—Å: {text}\n\n"
                    f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è #{article_id} –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n\n"
                    f"–¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏:\n{article_text}\n\n"
                    "–î–∞–π –∫—Ä–∞—Ç–∫–æ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏.")
    else:
        user_msg = (f"–í–æ–ø—Ä–æ—Å: {text}\n\n"
                    "–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π. –î–∞–π –æ–±—â–∏–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç –∏ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å https://lex.uz/docs/6257291 –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Ä–µ–¥–∞–∫—Ü–∏–∏.")

    # 5) Call GPT for the final answer
    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=0.15,
            max_tokens=700
        )
        answer = completion.choices[0].message.content.strip()
    except Exception as e:
        logging.exception("GPT error: %s", e)
        if article_text:
            answer = "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ù–∏–∂–µ ‚Äî –Ω–∞–π–¥–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è:\n\n" + article_text
        else:
            answer = "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

    # 6) Send response with header & lex link
    footer = "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–¥–∞–∫—Ü–∏—è: https://lex.uz/docs/6257291"
    if article_id and article_text:
        header = f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {article_id}\n\n"
        await message.answer(header + answer + footer)
    else:
        await message.answer(answer + footer)

    # 7) Logging
    try:
        conn = sqlite3.connect("logs.db")
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS logs(
                id INTEGER PRIMARY KEY,
                user_id INTEGER,
                username TEXT,
                question TEXT,
                answer TEXT,
                article INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cur.execute("""
            INSERT INTO logs(user_id, username, question, answer, article)
            VALUES(?,?,?,?,?)
        """, (
            uid,
            message.from_user.username or "",
            text,
            (("–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: " + str(article_id) + "\n\n") if article_id else "") + answer,
            int(article_id) if article_id else None
        ))
        conn.commit()
        conn.close()
    except Exception as e:
        logging.exception("Logging error: %s", e)

# ---------------------------
# Run
# ---------------------------
async def main():
    logging.basicConfig(level=logging.INFO)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
