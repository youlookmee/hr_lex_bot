import os
import re
import json
import logging
import asyncio
from pathlib import Path

import numpy as np
from numpy.linalg import norm

from aiogram import Bot, Dispatcher, F
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties
from aiogram.types import Message
from aiogram.filters import CommandStart

from openai import OpenAI

# =========================
# ENV
# =========================
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN not set")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY not set")

# =========================
# PATHS
# =========================
BASE_DIR = Path(__file__).resolve().parent
LAW_DIR = BASE_DIR / "law"

RU_JSON = LAW_DIR / "law_base_ru.json"
UZ_JSON = LAW_DIR / "law_base_uz.json"

RU_EMB = LAW_DIR / "embeddings_ru.pkl"
UZ_EMB = LAW_DIR / "embeddings_uz.pkl"

LEX_LINK = "https://lex.uz/docs/6257291"

# =========================
# BOT
# =========================
bot = Bot(token=TELEGRAM_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

# =========================
# LOAD BASES
# =========================
def load_json(path: Path) -> dict:
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

LAW_RU = load_json(RU_JSON)
LAW_UZ = load_json(UZ_JSON)

# =========================
# LOAD EMBEDDINGS (optional)
# =========================
def load_pkl(path: Path) -> dict:
    if path.exists():
        import pickle
        with open(path, "rb") as f:
            return pickle.load(f)
    return {}

EMB_RU = load_pkl(RU_EMB)
EMB_UZ = load_pkl(UZ_EMB)

# =========================
# UTILS
# =========================
def cosine(a, b):
    if norm(a) == 0 or norm(b) == 0:
        return -1.0
    return float(np.dot(a, b) / (norm(a) * norm(b)))

def detect_lang(text: str):
    # –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ -> ru
    if re.search(r"[–ê-–Ø–∞-—è–Å—ë]", text):
        return "ru"
    # —É–∑–±–µ–∫—Å–∫–∞—è –ª–∞—Ç–∏–Ω–∏—Ü–∞ (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
    low = text.lower()
    if any(k in low for k in ["modda", "mehnat", "ish", "shartnoma", "bekor", "ta'til", "maosh"]):
        return "uz"
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ru
    return "ru"

def extract_article_id(text: str):
    low = text.lower()
    # ru
    m = re.search(r"—Å—Ç–∞—Ç(?:—å—è|–∏)?\s*(\d{1,4})", low)
    if m:
        return m.group(1)
    # uz latin
    m = re.search(r"(\d{1,4})\s*-\s*modda|\bmodda\s*(\d{1,4})", low)
    if m:
        return m.group(1) or m.group(2)
    return None

async def semantic_pick(text: str, lang: str):
    # –µ—Å–ª–∏ embeddings –Ω–µ—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º
    vectors = EMB_RU if lang == "ru" else EMB_UZ
    if not vectors:
        return None

    emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    qv = np.array(emb.data[0].embedding)

    best_id, best_score = None, -1.0
    for aid, vec in vectors.items():
        sc = cosine(qv, np.array(vec))
        if sc > best_score:
            best_score, best_id = sc, aid

    # –ø–æ—Ä–æ–≥ –º–æ–∂–Ω–æ –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å
    return best_id if best_score >= 0.23 else None

# =========================
# HANDLERS
# =========================
@dp.message(CommandStart())
async def start(message: Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø HR-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –†–£–∑.\n\n"
        "–ü–∏—à–∏ –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ —É–∑–±–µ–∫—Å–∫–æ–º (–ª–∞—Ç–∏–Ω–∏—Ü–∞).\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ —Å—Ç–∞—Ç—å—è 157\n"
        "‚Ä¢ 157 modda\n"
        "‚Ä¢ —É–≤–æ–ª—å–Ω–µ–Ω–∏–µ –ø–æ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–µ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞\n"
        "‚Ä¢ mehnat shartnomasini bekor qilish\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {LEX_LINK}"
    )

@dp.message(F.text)
async def handle(message: Message):
    text = message.text.strip()
    if not text:
        return

    lang = detect_lang(text)
    law = LAW_RU if lang == "ru" else LAW_UZ

    # 1) —è–≤–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç–∞—Ç—å–∏
    aid = extract_article_id(text)
    article_text = None

    if aid and aid in law:
        article_text = law.get(aid)

    # 2) semantic search
    if not article_text:
        try:
            pick = await semantic_pick(text, lang)
            if pick and pick in law:
                aid = pick
                article_text = law.get(pick)
        except Exception:
            logging.exception("Semantic search failed")

    # 3) GPT –æ—Ç–≤–µ—Ç
    system_msg = (
        "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π HR-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –¢—Ä—É–¥–æ–≤–æ–º—É –∫–æ–¥–µ–∫—Å—É –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–∞. "
        "–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç–æ –∏ –ø–æ –¥–µ–ª—É. –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞—Ç—å—è ‚Äî –æ–±—ä—è—Å–Ω–∏ –µ—ë —Å–º—ã—Å–ª –∏ –ø—Ä–∞–∫—Ç–∏–∫—É."
    )

    if article_text:
        user_msg = (
            f"–Ø–∑—ã–∫: {lang}\n"
            f"–í–æ–ø—Ä–æ—Å: {text}\n\n"
            f"–¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏:\n{article_text}\n\n"
            "–î–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç."
        )
    else:
        user_msg = (
            f"–Ø–∑—ã–∫: {lang}\n"
            f"–í–æ–ø—Ä–æ—Å: {text}\n\n"
            "–°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç –∏ —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫."
        )

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.2,
            max_tokens=700,
        )
        answer = resp.choices[0].message.content.strip()
    except Exception as e:
        logging.exception("GPT error: %s", e)
        answer = "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

    # 4) —Ñ–∏–Ω–∞–ª
    header = f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {aid}\n\n" if article_text and aid else ""
    await message.answer(f"{header}{answer}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {LEX_LINK}")

# =========================
# RUN
# =========================
async def main():
    logging.basicConfig(level=logging.INFO)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
